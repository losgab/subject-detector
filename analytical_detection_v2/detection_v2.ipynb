{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "single_data = 1\n",
    "multi_data = 5\n",
    "more_data = 20\n",
    "even_more_data = 40\n",
    "full_data = 500\n",
    "\n",
    "current_data = more_data\n",
    "\n",
    "kmeans1_most_freq_pixel = {}\n",
    "\n",
    "# Dataset Path\n",
    "dataset_path = \"../dataset/train/\"\n",
    "\n",
    "# Padding Removed Directory\n",
    "dir_padding_removed = \"padding_removed\"\n",
    "# Image Processed Directory\n",
    "dir_preprocessed = \"preprocessed\"\n",
    "# HSV Converted Directory\n",
    "dir_hsv_converted = \"hsv_converted\"\n",
    "# K Means Segmented Directory\n",
    "dir_kmeans_segmented = \"kmeans_segmented\"\n",
    "# Processed Foregrounds Directory\n",
    "dir_processed_foregrounds = \"processed_foregrounds\"\n",
    "# Resulting Detected Objects\n",
    "dir_result = \"detected_objectsv2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove all white pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blackenPads(image):\n",
    "    image[np.where((image==[255,255,255]).all(axis=2))] = [0,0,0]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Remove White Padding Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove White Padding - Gabriel Thien - Computer Visionaries\n",
    "\n",
    "def removePads(image):\n",
    "    num_rows = image.shape[0]\n",
    "    num_cols = image.shape[1]\n",
    "    \n",
    "    grayscale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary_mask = cv2.threshold(grayscale, 240, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    corners = [(0, 0) for i in range(2)]\n",
    "    padding_exists = False\n",
    "    \n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        # print(f\"Contour 1: {(x, y)} -> {(x + w, y + h)}\")\n",
    "        if (x == 0 and y == 0):\n",
    "            if (x + w == num_cols): corners[0] = (x, y + h) # For vertical padding\n",
    "            else: corners[0] = (x + w, y) # For horizontal padding\n",
    "            padding_exists = True\n",
    "        elif (x + w >= num_cols and y + h >= num_rows):\n",
    "            if (y == 0): corners[1] = (x, y + h) # For vertical padding\n",
    "            else: corners[1] = (x + w, y) # For horizontal padding\n",
    "            padding_exists = True\n",
    "\n",
    "    if padding_exists:\n",
    "        # Displays the targeted image\n",
    "        top_left_corner = corners[0]\n",
    "        bottom_right_corner = corners[1]\n",
    "        # cv2.rectangle(image, top_left_corner, bottom_right_corner, (0, 255, 0), 2)  # Green rectangle\n",
    "        # cv2.imshow(\"Image Targeted\", image)\n",
    "    \n",
    "        cropped_image = image[top_left_corner[1]:bottom_right_corner[1], top_left_corner[0]:bottom_right_corner[0]]\n",
    "        # cv2.imshow(\"Cropped Image\", cropped_image)\n",
    "        # cv2.waitKey(0)\n",
    "        # cv2.destroyAllWindows()\n",
    "        # cv2.waitKey(1)\n",
    "        return cropped_image\n",
    "    else: return image\n",
    "\n",
    "input_directory_path = dataset_path\n",
    "output_directory_path = dir_padding_removed\n",
    "\n",
    "if os.path.exists(output_directory_path) and os.path.isdir(output_directory_path):\n",
    "    pass\n",
    "else: \n",
    "    os.mkdir(output_directory_path)\n",
    "\n",
    "# Change this to process more images\n",
    "for i in range(current_data):\n",
    "    image_path = input_directory_path + f\"image_id_{i:03d}.jpg\"\n",
    "    training_image = cv2.imread(image_path)\n",
    "    # output = removePads(training_image)\n",
    "    output = blackenPads(training_image)\n",
    "    cv2.imwrite(output_directory_path + f\"/result{i:03d}.png\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_directory_path = dir_padding_removed\n",
    "output_directory_path = dir_preprocessed\n",
    "\n",
    "if os.path.exists(output_directory_path) and os.path.isdir(output_directory_path):\n",
    "    pass\n",
    "else: \n",
    "    os.mkdir(output_directory_path)\n",
    "\n",
    "def sharpen(image, iterations=1):\n",
    "    kernel = np.array([[0, -1, 0],\n",
    "                       [-1, 5, -1],\n",
    "                       [0, -1, 0]])\n",
    "\n",
    "    for i in range(iterations):\n",
    "        image = cv2.filter2D(image, -1, kernel)\n",
    "\n",
    "    return image\n",
    "\n",
    "def changeSaturation(image, saturation_factor):\n",
    "    # Convert BGR image to HSV color space\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Split the HSV image into separate channels\n",
    "    h, s, v = cv2.split(hsv_image)\n",
    "\n",
    "    # Increase saturation (clip to ensure valid range of [0, 255])\n",
    "    s = np.clip(s * saturation_factor, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # Merge the modified saturation channel back with the other channels\n",
    "    hsv_adjusted = cv2.merge((h, s, v))\n",
    "\n",
    "    # Convert the HSV-adjusted image back to BGR color space\n",
    "    adjusted_image = cv2.cvtColor(hsv_adjusted, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    return adjusted_image\n",
    "\n",
    "saturation_factor = 4\n",
    "\n",
    "for i in range(current_data):\n",
    "    imagePath = input_directory_path + f\"/result{i:03d}.png\"\n",
    "    input_image = cv2.imread(imagePath)\n",
    "    \n",
    "    sharper = sharpen(input_image)\n",
    "\n",
    "    saturated = changeSaturation(sharper, saturation_factor)\n",
    "\n",
    "    # cv2.imshow(\"Contrasted\", contrasted)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    # cv2.waitKey(1)\n",
    "    \n",
    "    cv2.imwrite(output_directory_path + f\"/result{i:03d}.png\", saturated)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HSV Generator\n",
    "- Output: (hsv_padding_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blurring & Generating HSVs - Gabriel Thien - Computer Visionaries\n",
    "\n",
    "input_directory_path = dir_preprocessed\n",
    "output_directory_path = dir_hsv_converted\n",
    "\n",
    "if os.path.exists(output_directory_path) and os.path.isdir(output_directory_path):\n",
    "    pass\n",
    "else: \n",
    "    os.mkdir(output_directory_path)\n",
    "\n",
    "for i in range(current_data):\n",
    "    imagePath = input_directory_path + f\"/result{i:03d}.png\"\n",
    "    input_image = cv2.imread(imagePath)\n",
    "    hsv_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Blurring\n",
    "    kernel_size_mean = (3, 3)\n",
    "    hsv_blurred = cv2.blur(hsv_image, kernel_size_mean)\n",
    "    \n",
    "    # cv2.imshow(\"Blurrer HSV\", hsv_blurred)\n",
    "    # cv.waitKey(0)\n",
    "    # cv.destroyAllWindows()\n",
    "    # cv.waitKey(1)\n",
    "    \n",
    "    cv2.imwrite(output_directory_path + f\"/result{i:03d}.png\", hsv_blurred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Means Segmented\n",
    "- Output: hsv_kmeans_segmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colour Segmentation - Gabriel Thien - Computer Visionaries\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def makeFlattenedMatrix(image):\n",
    "    pixels = []\n",
    "    \n",
    "    for row in image:\n",
    "        for rgb_pixel in row:\n",
    "            pixels.append((rgb_pixel[0], rgb_pixel[1], rgb_pixel[2]))\n",
    "\n",
    "    return np.array(pixels)    \n",
    "    \n",
    "\n",
    "def kMeansSegment(imagePath):\n",
    "    image = cv2.imread(imagePath)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    pixels = makeFlattenedMatrix(image_rgb)\n",
    "\n",
    "    # K means clustering\n",
    "    K = 4\n",
    "    n = 2\n",
    "    # Perform K-means clustering\n",
    "    kmeans = KMeans(n_init=n, n_clusters=K, random_state=0)\n",
    "    kmeans.fit(pixels)\n",
    "\n",
    "    cluster_centers = kmeans.cluster_centers_\n",
    "    labels = kmeans.labels_\n",
    "    # print(cluster_centers)\n",
    "    # print(labels)\n",
    "\n",
    "    # Create the segmented image\n",
    "    segmented_image = cluster_centers[labels].reshape(image.shape).astype(np.uint8)\n",
    "    \n",
    "    return segmented_image\n",
    "\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "# cv2.waitKey(1)\n",
    "\n",
    "input_directory_path = dir_hsv_converted\n",
    "output_directory_path = dir_kmeans_segmented\n",
    "\n",
    "if os.path.exists(output_directory_path) and os.path.isdir(output_directory_path):\n",
    "    pass\n",
    "else: \n",
    "    os.mkdir(output_directory_path)\n",
    "\n",
    "for i in range(current_data):\n",
    "    imagePath = input_directory_path + f\"/result{i:03d}.png\"\n",
    "    result = kMeansSegment(imagePath)\n",
    "    cv2.imwrite(output_directory_path + f\"/result{i:03d}.png\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining colour frequencies of a segmented image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing Colours - Gabriel Thien - Computer Visionaries\n",
    "\n",
    "def computePixelFrequencies(image) -> list:\n",
    "    pixels = {}\n",
    "    for row in image:\n",
    "        for pixel in row:\n",
    "            if tuple(pixel) in pixels.keys():\n",
    "                pixels[tuple(pixel)] += 1\n",
    "            else:\n",
    "                pixels[tuple(pixel)] = 1\n",
    "\n",
    "    return sorted(pixels.items(), key=lambda x: x[1])\n",
    "\n",
    "\n",
    "def isolateColour(image, colours: list):\n",
    "\n",
    "    # black_image = np.zeros((num_rows, num_cols, 3), dtype=np.uint8)\n",
    "\n",
    "    image_copy = image.copy()\n",
    "    pure_colours = [colours[i][0] for i in range(len(colours))]\n",
    "\n",
    "    # Colours - FOUR\n",
    "    # colour_low = tuple(colours[0][0])\n",
    "    # colour_mid = tuple(colours[1][0])\n",
    "    # colour_high = tuple(colours[2][0])\n",
    "    # colour_max = tuple(colours[3][0])\n",
    "    \n",
    "    # Colours - THREE\n",
    "    # colour_low = tuple(colours[0][0])\n",
    "    # colour_mid = tuple(colours[1][0])\n",
    "    # colour_high = tuple(colours[2][0])\n",
    "    # print(colour_low)\n",
    "\n",
    "    # Colours - TWO\n",
    "    # colour_low = tuple(colours[0][0])\n",
    "    # colour_high = tuple(colours[1][0])\n",
    "\n",
    "    # Redo Colours\n",
    "    for i in range(len(colours)):\n",
    "        pixel = colours[i][0]\n",
    "        if (pixel[0] <= 20 and pixel[1] <= 20 and pixel[2] <= 20):\n",
    "            colours.remove(colours[i])\n",
    "            break\n",
    "    \n",
    "    colour_low = tuple(colours[0][0])\n",
    "    colour_mid = tuple(colours[1][0])\n",
    "    colour_high = tuple(colours[2][0])\n",
    "\n",
    "    # K1\n",
    "    kernel = np.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]], dtype=np.uint8)\n",
    "\n",
    "    # K2\n",
    "    # kernel = np.array([[1, 1, 1], [1, 0, 1], [1, 1, 1]], dtype=np.uint8)\n",
    "\n",
    "    # K3\n",
    "    # kernel = np.ones((3, 3), np.uint8)\n",
    "\n",
    "    # Original\n",
    "    # cv2.imshow(\"Original\", image)\n",
    "\n",
    "    # Foreground stuff\n",
    "    # foreground_colour = preserveSingleColour(image_copy, colour_low)\n",
    "    foreground = preserveDoubleColour(image_copy, colour_low, colour_mid)\n",
    "    foreground = cv2.erode(foreground, kernel, iterations=10)\n",
    "    foreground = cv2.dilate(foreground, kernel, iterations=4)\n",
    "\n",
    "    # # Midground stuff\n",
    "    # midground_colour = preserveSingleColour(image_copy, colour_mid)\n",
    "\n",
    "    # Background stuff\n",
    "    # background_colour = preserveSingleColour(image_copy, colour_high)\n",
    "    # background_dilated = cv2.dilate(background_colour, kernel, iterations=20)\n",
    "    # background_eroded = cv2.erode(background_dilated, kernel, iterations=20)\n",
    "    # background_focused_image = cv2.bitwise_not(background_eroded)\n",
    "\n",
    "    # cv2.imshow(\"Foreground Colour\", foreground_colour)\n",
    "    # cv2.imshow(\"Eroded\", foreground_eroded)\n",
    "    # cv2.imshow(\"Foreground\", foreground_focused_image)\n",
    "\n",
    "    # cv2.imshow(\"Background Colour\", background_colour)\n",
    "    # cv2.imshow(\"Background Dilated\", background_dilated)\n",
    "    # cv2.imshow(\"Background Eroded\", background_eroded)\n",
    "    # cv2.imshow(\"Background\", background_focused_image)\n",
    "\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    # cv2.waitKey(1)\n",
    "    return foreground\n",
    "\n",
    "\n",
    "def preserveSingleColour(image, targetPixel: tuple):\n",
    "    image_copy = image.copy()\n",
    "\n",
    "    # Pixel mask that isnt the target pixel\n",
    "    mask = np.all(image_copy != targetPixel, axis=2)\n",
    "    # Applies mask\n",
    "    image_copy[mask] = [0, 0, 0]\n",
    "\n",
    "    # cv2.imshow(\"Grayscale single channel\", grayscale)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    # cv2.waitKey(1)\n",
    "    return image_copy\n",
    "\n",
    "\n",
    "def preserveDoubleColour(image, targetPixel1: tuple, targetPixel2: tuple):\n",
    "    foreground = image.copy()\n",
    "    midground = image.copy()\n",
    "\n",
    "    # Pixel mask that isnt the target pixel\n",
    "    foreground_mask = np.all(foreground != targetPixel1, axis=2)\n",
    "    mid_ground_mask = np.all(midground != targetPixel2, axis=2)\n",
    "    # Applies mask\n",
    "    foreground[foreground_mask] = [0, 0, 0]\n",
    "    midground[mid_ground_mask] = [0, 0, 0]\n",
    "    result = cv2.add(foreground, midground)\n",
    "\n",
    "    # cv2.imshow(\"Grayscale single channel\", grayscale)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    # cv2.waitKey(1)\n",
    "    return result\n",
    "\n",
    "\n",
    "def defaultBackground(image, colours: tuple, tolerance=20):\n",
    "    num_rows = image.shape[0]\n",
    "    num_cols = image.shape[1]\n",
    "\n",
    "    most_common_colour = colours[-1][0]\n",
    "\n",
    "    for x in range(num_rows):\n",
    "        for y in range(num_cols):\n",
    "            pixel = image[x][y]\n",
    "            if (\n",
    "                pixel[0] <= tolerance\n",
    "                and pixel[1] <= tolerance\n",
    "                and pixel[2] <= tolerance\n",
    "            ):\n",
    "                image[x][y] = most_common_colour\n",
    "\n",
    "    return image\n",
    "\n",
    "def removeBackground(image, colours: tuple):\n",
    "    num_rows = image.shape[0]\n",
    "    num_cols = image.shape[1]\n",
    "\n",
    "    most_common_colour = colours[-1][0]\n",
    "\n",
    "    for x in range(num_rows):\n",
    "        for y in range(num_cols):\n",
    "            pixel = image[x][y]\n",
    "            if tuple(pixel) == most_common_colour:\n",
    "                image[x][y] = (0, 0, 0)\n",
    "\n",
    "    colours.pop()\n",
    "    \n",
    "    return image, colours\n",
    "\n",
    "\n",
    "input_directory_path = dir_kmeans_segmented\n",
    "output_directory_path = dir_processed_foregrounds\n",
    "\n",
    "if os.path.exists(output_directory_path) and os.path.isdir(output_directory_path):\n",
    "    pass\n",
    "else: \n",
    "    os.mkdir(output_directory_path)\n",
    "\n",
    "for i in range(current_data):\n",
    "    imagePath = input_directory_path + f\"/result{i:03d}.png\"\n",
    "    image = cv2.imread(imagePath)\n",
    "\n",
    "    pixel_frequencies = computePixelFrequencies(image)\n",
    "    # print(f\"Number of pixel groups for image {i}: {len(pixel_frequencies)}, {pixel_frequencies}\")\n",
    "\n",
    "    most_frequent_pixel = pixel_frequencies[-1][0]\n",
    "    kmeans1_most_freq_pixel[i] = most_frequent_pixel\n",
    "\n",
    "    defaulted_background = defaultBackground(image, pixel_frequencies)\n",
    "\n",
    "    # Isolate foreground based on pixel frequencies\n",
    "    processed_image = isolateColour(defaulted_background, pixel_frequencies)\n",
    "\n",
    "    cv2.imwrite(output_directory_path + f\"/result{i:03d}.png\", processed_image)\n",
    "\n",
    "    # cv2.imshow(f\"Processed Image\", processed_image)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    # cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drawing Bounding Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw Bounding Boxes - Gabriel Thien - Computer Visionaries\n",
    "# Image has been segmented and the outline of the image is ready to be highlighted\n",
    "\n",
    "def getContours(image):\n",
    "    grayscale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    _, thresholded = cv2.threshold(grayscale, 0, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # print(f\"Type of contours: {type(contours)}\")\n",
    "    return contours\n",
    "\n",
    "# All areas\n",
    "def calculateBoundingBox(contours):\n",
    "    x_min = x_max = 0\n",
    "    y_min = y_max = 0\n",
    "    \n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if (x_min == 0) and (x_max == 0) and (y_min == 0) and (y_max == 0):\n",
    "            x_min = x\n",
    "            x_max = x + w\n",
    "            y_min = y\n",
    "            y_max = y + h\n",
    "        if (x < x_min): x_min = x\n",
    "        elif (x + w > x_max): x_max = x + w\n",
    "        if (y < y_min): y_min = y\n",
    "        elif (y + h > y_max): y_max = y + h\n",
    "        \n",
    "    return (x_min, y_min), (x_max, y_max)\n",
    "\n",
    "def drawBoundingBox(island_image, original_image):\n",
    "    contours = getContours(island_image)\n",
    "\n",
    "    top_left_corner, bottom_right_corner = calculateBoundingBox(contours)\n",
    "\n",
    "    drawn = cv2.rectangle(original_image, top_left_corner, bottom_right_corner, (0, 255, 0), 2)\n",
    "    return drawn\n",
    "\n",
    "input_directory_path = dir_processed_foregrounds\n",
    "output_directory_path = dir_result\n",
    "\n",
    "if os.path.exists(output_directory_path) and os.path.isdir(output_directory_path):\n",
    "    pass\n",
    "else: \n",
    "    os.mkdir(output_directory_path)\n",
    "\n",
    "for i in range(current_data):\n",
    "    islandImagePath = input_directory_path + f\"/result{i:03d}.png\"\n",
    "    island_image = cv2.imread(islandImagePath)\n",
    "    \n",
    "    originalImagePath = dataset_path + f\"image_id_{i:03d}.jpg\"\n",
    "    original_image = cv2.imread(originalImagePath)\n",
    "    \n",
    "    drawn_image = drawBoundingBox(island_image, original_image)\n",
    "        \n",
    "    cv2.imwrite(output_directory_path + f\"/detectedv2_{i:03d}.png\", drawn_image)\n",
    "    # cv2.imshow(\"Drawn Image\", drawn_image)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    # cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
